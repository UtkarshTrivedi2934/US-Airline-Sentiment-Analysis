{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20551f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d32300",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aae71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment    airline airline_sentiment_gold  \\\n",
       "0  567900433542488064          negative  Southwest                    NaN   \n",
       "1  569989168903819264          positive  Southwest                    NaN   \n",
       "2  568089179520954368          positive     United                    NaN   \n",
       "3  568928195581513728          negative  Southwest                    NaN   \n",
       "4  568594180014014464          negative     United                    NaN   \n",
       "\n",
       "            name negativereason_gold  retweet_count  \\\n",
       "0  ColeyGirouard                 NaN              0   \n",
       "1  WalterFaddoul                 NaN              0   \n",
       "2      LocalKyle                 NaN              0   \n",
       "3    amccarthy19                 NaN              0   \n",
       "4        J_Okayy                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @SouthwestAir I am scheduled for the morning, ...         NaN   \n",
       "1  @SouthwestAir seeing your workers time in and ...         NaN   \n",
       "2  @united Flew ORD to Miami and back and  had gr...         NaN   \n",
       "3     @SouthwestAir @dultch97 that's horse radish üò§üê¥         NaN   \n",
       "4  @united so our flight into ORD was delayed bec...         NaN   \n",
       "\n",
       "               tweet_created              tweet_location  \\\n",
       "0  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3  2015-02-20 16:20:26 -0800                         NaN   \n",
       "4  2015-02-19 18:13:11 -0800                         NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0      Atlantic Time (Canada)  \n",
       "1  Central Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3      Atlantic Time (Canada)  \n",
       "4  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68aade08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.text\n",
    "y_train = train.airline_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9dd0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d590a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10980,), (10980,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape , x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915d158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079231f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "805711a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'!',\n",
       "  '\"',\n",
       "  '#',\n",
       "  '$',\n",
       "  '%',\n",
       "  '&',\n",
       "  \"'\",\n",
       "  '(',\n",
       "  ')',\n",
       "  '*',\n",
       "  '+',\n",
       "  ',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '/',\n",
       "  ':',\n",
       "  ';',\n",
       "  '<',\n",
       "  '=',\n",
       "  '>',\n",
       "  '?',\n",
       "  '@',\n",
       "  '[',\n",
       "  '\\\\',\n",
       "  ']',\n",
       "  '^',\n",
       "  '_',\n",
       "  '`',\n",
       "  'a',\n",
       "  'about',\n",
       "  'above',\n",
       "  'after',\n",
       "  'again',\n",
       "  'against',\n",
       "  'ain',\n",
       "  'all',\n",
       "  'am',\n",
       "  'an',\n",
       "  'and',\n",
       "  'any',\n",
       "  'are',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'as',\n",
       "  'at',\n",
       "  'be',\n",
       "  'because',\n",
       "  'been',\n",
       "  'before',\n",
       "  'being',\n",
       "  'below',\n",
       "  'between',\n",
       "  'both',\n",
       "  'but',\n",
       "  'by',\n",
       "  'can',\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'd',\n",
       "  'did',\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'do',\n",
       "  'does',\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'doing',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'down',\n",
       "  'during',\n",
       "  'each',\n",
       "  'few',\n",
       "  'for',\n",
       "  'from',\n",
       "  'further',\n",
       "  'had',\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'has',\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'have',\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'having',\n",
       "  'he',\n",
       "  'her',\n",
       "  'here',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'him',\n",
       "  'himself',\n",
       "  'his',\n",
       "  'how',\n",
       "  'i',\n",
       "  'if',\n",
       "  'in',\n",
       "  'into',\n",
       "  'is',\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'just',\n",
       "  'll',\n",
       "  'm',\n",
       "  'ma',\n",
       "  'me',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'more',\n",
       "  'most',\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'my',\n",
       "  'myself',\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'now',\n",
       "  'o',\n",
       "  'of',\n",
       "  'off',\n",
       "  'on',\n",
       "  'once',\n",
       "  'only',\n",
       "  'or',\n",
       "  'other',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'out',\n",
       "  'over',\n",
       "  'own',\n",
       "  're',\n",
       "  's',\n",
       "  'same',\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'so',\n",
       "  'some',\n",
       "  'such',\n",
       "  't',\n",
       "  'than',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'the',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'them',\n",
       "  'themselves',\n",
       "  'then',\n",
       "  'there',\n",
       "  'these',\n",
       "  'they',\n",
       "  'this',\n",
       "  'those',\n",
       "  'through',\n",
       "  'to',\n",
       "  'too',\n",
       "  'under',\n",
       "  'until',\n",
       "  'up',\n",
       "  've',\n",
       "  'very',\n",
       "  'was',\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'we',\n",
       "  'were',\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'what',\n",
       "  'when',\n",
       "  'where',\n",
       "  'which',\n",
       "  'while',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'why',\n",
       "  'will',\n",
       "  'with',\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\",\n",
       "  'y',\n",
       "  'you',\n",
       "  \"you'd\",\n",
       "  \"you'll\",\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  '{',\n",
       "  '|',\n",
       "  '}',\n",
       "  '~'},\n",
       " '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)\n",
    "stops, string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d42f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stops:\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return \" \".join(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "531e0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "x_train = [clean_review(word_tokenize(i)) for i in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eded9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.text\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d98c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [ clean_review(word_tokenize(i)) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "116fbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1d87f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(analyzer = 'word',max_features = 3150,max_df = 0.8,ngram_range=(1,1))\n",
    "train_features= v.fit_transform(x_train)\n",
    "test_features=v.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "039b23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "classifier_sklearn1 = SklearnClassifier(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07bdf3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_features.todense()\n",
    "x_train = train_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14635c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(train_features , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b78e840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30f27602",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"sentiments.csv\" , y_pred , fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
